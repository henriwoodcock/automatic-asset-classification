{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic_Autoencoder_w_clustering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3xTqAKCPCmp",
        "colab_type": "code",
        "outputId": "bf0533c4-5f09-4816-97e0-ee2bf7981e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!pip install \"torch==1.4\" \"torchvision==0.5.0\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 22kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.18.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.0+cu101\n",
            "    Uninstalling torch-1.5.0+cu101:\n",
            "      Successfully uninstalled torch-1.5.0+cu101\n",
            "  Found existing installation: torchvision 0.6.0+cu101\n",
            "    Uninstalling torchvision-0.6.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.0+cu101\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGOTlOQ_DWa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "import torch\n",
        "from torch import nn\n",
        "import imageio\n",
        "from fastai.vision import *\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0053E8pDyhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = False)\n",
        "%cd \"/content/drive/My Drive/automatic-asset-classification\"\n",
        "#%cp \"/content/drive/My Drive/automatic-asset-classification/data/final_dataset\" .\n",
        "%ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNcXM4xuD3nH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(3333)\n",
        "torch.manual_seed(3333)\n",
        "image_path = \"data/final_dataset\"\n",
        "size = 224\n",
        "batchsize = 32\n",
        "\n",
        "tfms = get_transforms(do_flip = True)\n",
        "src = (ImageImageList.from_folder(image_path).split_by_rand_pct().label_from_func(lambda x: x))\n",
        "data = (src.transform(tfms, size=size, tfm_y=True)\n",
        "        .databunch(bs=batchsize)\n",
        "        .normalize(imagenet_stats, do_y = False))\n",
        "print(\"imported\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b20h-CbHOuCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dbOXnPhELaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.callbacks import *\n",
        "from fastai.utils.mem import *\n",
        "from torchvision.models import vgg16_bn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from fastai.torch_core import requires_grad, children\n",
        "\n",
        "def gram_matrix(x):\n",
        "    n,c,h,w = x.size()\n",
        "    x = x.view(n, c, -1)\n",
        "    return (x @ x.transpose(1,2))/(c*h*w)\n",
        "\n",
        "\n",
        "class FeatureLoss(nn.Module):\n",
        "    def __init__(self, m_feat, layer_ids, layer_wgts, base_loss):\n",
        "        super().__init__()\n",
        "        self.m_feat = m_feat\n",
        "        self.base_loss = base_loss\n",
        "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
        "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
        "        self.wgts = layer_wgts\n",
        "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
        "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
        "\n",
        "    def make_features(self, x, clone=False):\n",
        "        self.m_feat(x)\n",
        "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        out_feat = self.make_features(target, clone=True)\n",
        "        in_feat = self.make_features(input)\n",
        "        self.feat_losses = [self.base_loss(input,target)]\n",
        "        self.feat_losses += [self.base_loss(f_in, f_out)*w\n",
        "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
        "        self.feat_losses += [self.base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
        "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
        "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
        "        return sum(self.feat_losses)\n",
        "\n",
        "    def __del__(self): self.hooks.remove()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INTW8pBTFIbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from fastai.torch_core import *\n",
        "from fastai.core import ifnone\n",
        "from fastai.layers import *\n",
        "\n",
        "class reshape(nn.Module):\n",
        "    '''a torch layer to reshape the input into size = shape = type list'''\n",
        "    def __init__(self, shape):\n",
        "        super(reshape, self).__init__()\n",
        "        self.shape = shape\n",
        "    def forward(self, x): return x.reshape(self.shape)\n",
        "\n",
        "class convblock(nn.Module):\n",
        "    '''\n",
        "    a convolutional block used in the model:\n",
        "    conv(in, out) -> batchnorm(out) -> relu\n",
        "    '''\n",
        "    def __init__(self, in_:int, out:int):\n",
        "      super().__init__()\n",
        "      self.conv1 = nn.Conv2d(in_, out, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      self.bn = nn.BatchNorm2d(out, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv1(x)\n",
        "      x = self.bn(x)\n",
        "      x = self.relu(x)\n",
        "      return x\n",
        "\n",
        "class downsamp(nn.Module):\n",
        "    ''' a downsampling block. using adaptive max pooling so select the size to be outputted and the scale you would like output ie out (3,10,10) is a downsamp(3, 10).\n",
        "    '''\n",
        "    def __init__(self, size:int, scale:int=2):\n",
        "      super().__init__()\n",
        "      self.pool = nn.AdaptiveMaxPool2d(scale)\n",
        "      self.bn = nn.BatchNorm2d(size, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      self.relu = nn.ReLU(inplace = True)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = self.pool(x)\n",
        "      x = self.bn(x)\n",
        "      x = self.relu(x)\n",
        "      return x\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "    '''\n",
        "    upsample by scale = scale. Ins and outs are input. Upsampling method is nearest neighbour.\n",
        "    '''\n",
        "    def __init__(self, in_:int, out:int, scale:int=2):\n",
        "      super().__init__()\n",
        "      self.upsample = nn.Upsample(scale_factor=scale, mode='nearest')\n",
        "      self.bn = nn.BatchNorm2d(in_, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      self.conv1 = nn.Sequential(\n",
        "              nn.Conv2d(in_, out, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "              nn.BatchNorm2d(out, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "              nn.ReLU(inplace=True)\n",
        "              )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.upsample(x)\n",
        "      x = self.bn(x)\n",
        "      x = self.conv1(x)\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5-Xq36HEmUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(encoder, self).__init__()\n",
        "        self.convblock1 = convblock(3,12)\n",
        "        self.convblock2 = convblock(12,12)\n",
        "        self.downsamp1 = downsamp(12, 112)\n",
        "        self.convblock3 = convblock(12, 24)\n",
        "        self.downsamp2 = downsamp(24, 16)\n",
        "\n",
        "        self.bottleneck = nn.Sequential(nn.Flatten(), \n",
        "                                        nn.Linear(24 * 16 * 16, 1568),\n",
        "                                        nn.Linear(1568,1024))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.downsamp1(x)\n",
        "\n",
        "        x = self.convblock3(x)\n",
        "        x = self.downsamp2(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(decoder, self).__init__()\n",
        "\n",
        "        self.bottleneck = nn.Sequential(nn.Linear(1024, 1568),\n",
        "                                        nn.Linear(1568, 24*16*16),\n",
        "                                        reshape([-1,24,16,16])\n",
        "                                        )\n",
        "\n",
        "        self.up1 = Upsample(24,12,7)\n",
        "        self.convblock1= convblock(12,12)\n",
        "        self.up3 = Upsample(12,3)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.bottleneck(x)\n",
        "        x = self.up1(x)\n",
        "        x = self.convblock1(x)\n",
        "        x = self.up3(x)\n",
        "        return x\n",
        "\n",
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "\n",
        "        self.encoder = encoder()\n",
        "        self.decoder = decoder()\n",
        "\n",
        "    def encode(self, x): return self.encoder(x)\n",
        "    def decode(self, x): return torch.clamp(self.decoder(x), min = 0, max = 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return torch.clamp(x, min = 0, max = 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFJFE-M5M4-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AE=autoencoder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_gGUE11OUxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg_m = vgg16_bn(True).features.cuda().eval()\n",
        "\n",
        "requires_grad(vgg_m, False)\n",
        "blocks = [i-1 for i,o in enumerate(children(vgg_m)) if isinstance(o,nn.MaxPool2d)]\n",
        "\n",
        "base_loss = F.mse_loss\n",
        "\n",
        "feat_loss = FeatureLoss(vgg_m, blocks[0:3], [30,20,10], base_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7UtpvHGOHCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data,AE,loss_func=feat_loss,metrics=[mean_squared_error, mean_absolute_error])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ7UJVgrOgpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuhA59PPez3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEIjjjOWe2Qt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.recorder.plot(suggestion=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJOMx8NUe6G3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(10, max_lr = 1e-02)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp_qXX3sxwtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.show_results(ds_type=DatasetType.Train, rows=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUAIxCF1hw4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.show_results(ds_type=DatasetType.Valid,rows=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAKzAbBaJHTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Autoencoder2(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Autoencoder2, self).__init__()\n",
        "        \n",
        "        self.convblock1 = convblock(3,12)\n",
        "        self.convblock2 = convblock(12,12)\n",
        "        self.downsamp1 = downsamp(12, 112)\n",
        "\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "            nn.BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "            nn.BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size = (2,2), stride = (2,2)),\n",
        "            nn.BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "            nn.BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveMaxPool2d(16),\n",
        "            nn.BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(24 * 16 * 16, 1568),\n",
        "            nn.Linear(1568, 1024)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(1024, 1568),\n",
        "            nn.Linear(1568, 24 * 16 * 16),\n",
        "            reshape([-1,24,16,16]),\n",
        "            nn.Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "            nn.BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            PixelShuffle_ICNR(12, 12, scale=7),\n",
        "            nn.BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            PixelShuffle_ICNR(12, 3),\n",
        "            nn.BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        \n",
        "    def encode(self,x): return self.encoder(x)\n",
        "    \n",
        "    def decode(self,x): return torch.clamp(self.decoder(x), min = 0, max=1)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return torch.clamp(decoded, min=0, max=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67QTBzq9jLZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ae2 = Autoencoder2()\n",
        "learn2 = Learner(data, ae2, loss_func = F.mse_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuoUWV2CjSJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn2.fit_one_cycle(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2Cjx1M-jVdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn2.lr_find()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqn6I1g5j-CW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn2.recorder.plot(suggestion=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC9eu6s4kAmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn2.fit_one_cycle(10, max_lr=1e-02)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "530JqiMhlfTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn2.show_results(ds_type=DatasetType.Train,rows=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcc337YVmPMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn2.show_results(ds_type=DatasetType.Valid,rows=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cXkLCFDnUUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(learn.model, \"model1.pt\")\n",
        "torch.save(learn2.model, \"model2.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoC5FwQ1nlMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder1, self).__init__()\n",
        "        self.encoder = torch.load(\"model1.pt\").encoder\n",
        "        \n",
        "    def encode(self,x): return self.encoder(x)\n",
        "    \n",
        "    def decode(self,x): return torch.clamp(self.decoder(x), min = 0, max=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        return encoded\n",
        "\n",
        "class Encoder2(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Encoder2, self).__init__()  \n",
        "        self.encoder = torch.load(\"model2.pt\").encoder\n",
        "        \n",
        "    def encode(self,x): return self.encoder(x)        \n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        return encoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvqx-4vroCnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ec1,ec2 = Encoder1(), Encoder2()\n",
        "enc1=Learner(data, ec1,loss_func=F.mse_loss)\n",
        "enc2=Learner(data, ec2,loss_func=F.mse_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJN8ewSRoRgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_1,acts_1=enc1.get_preds()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNlIfxjB2n1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acts_1.shape, preds_1.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJGHWRVrygb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_2,acts_2=enc2.get_preds()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0BweqH6mfVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster_data_1 = preds_1.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2c_HiaBmwJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster_data_std_1 = (cluster_data_1 - cluster_data_1.mean())/cluster_data_1.std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egnCFnjgm08a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster_data_2 = preds_2.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF1rcL8Um3hy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster_data_std_2 = (cluster_data_2 - cluster_data_2.mean())/cluster_data_2.std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxPdbCOem6Wq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=50)\n",
        "cluster_data_pca_1 = pca.fit_transform(cluster_data_std_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fefkOu90nEng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=50)\n",
        "cluster_data_pca_2 = pca.fit_transform(cluster_data_std_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9kTbPzE2_JB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster_data_std_2.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97idJlyx3MIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster_data_std_1.shape"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}