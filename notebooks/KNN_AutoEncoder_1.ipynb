{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngMA7VJgdyqn"
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.tabular import *\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "from torch import nn\n",
    "import imageio\n",
    "import torch\n",
    "import glob\n",
    "from fastai.vision import *\n",
    "import os\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "7Lk3qLYqeM4n",
    "outputId": "5aae8e07-2be5-469f-8f0c-89fc0a0ac70a"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount = True)\n",
    "    %cd \"/content/drive/My Drive/automatic-asset-classification\"\n",
    "    %ls \"/content/drive/My Drive/automatic-asset-classification\"\n",
    "    image_path = \"/content/drive/My Drive/automatic-asset-classification/data/final_dataset\"\n",
    "    \n",
    "if not colab:\n",
    "    image_path = '/Users/henriwoodcock/Documents/Code/data_projects/automatic-asset-classification/data/'\\\n",
    "                 'final_dataset/final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0LB-1hseQFF"
   },
   "outputs": [],
   "source": [
    "size = 224\n",
    "batchsize = 32\n",
    "tfms = get_transforms(do_flip = False)\n",
    "src = (ImageImageList.from_folder(image_path).split_by_rand_pct(seed=2).label_from_func(lambda x: x))\n",
    "data = (src.transform(size=size, tfm_y=True)\n",
    "        .databunch(bs=batchsize)\n",
    "        .normalize(imagenet_stats, do_y = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XzCQ1kWfecxq"
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False);\n",
    "        self.batch1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True);\n",
    "        \n",
    "        self.up1 = nn.Upsample(scale_factor = 2, mode = 'bilinear');\n",
    "        self.conv2 = nn.Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False);\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        return nn.Sequential(self.conv1, self.batch1, self.relu)(x)\n",
    "    \n",
    "    def decoder(self, x):\n",
    "        return nn.Sequential(self.up1,self.conv2, self.relu)(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, autoencoder, loss_func=F.mse_loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='8', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      12.50% [1/8 01:38<11:28]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.246415</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8' class='' max='13', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      61.54% [8/13 01:01<00:38 0.2450]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "09DZgbgWefPv",
    "outputId": "07c52a59-f0e0-47b4-b183-116b2fd87ce5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (387 items)\n",
       "x: ImageImageList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: ImageList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "Path: /content/drive/My Drive/automatic-asset-classification/data/final_dataset;\n",
       "\n",
       "Valid: LabelList (96 items)\n",
       "x: ImageImageList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: ImageList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "Path: /content/drive/My Drive/automatic-asset-classification/data/final_dataset;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JItBtzIBeO2H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KNN-AutoEncoder-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
