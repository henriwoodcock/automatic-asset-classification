{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngMA7VJgdyqn"
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.tabular import *\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "from torch import nn\n",
    "import imageio\n",
    "import torch\n",
    "import glob\n",
    "from fastai.vision import *\n",
    "import os\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "7Lk3qLYqeM4n",
    "outputId": "5aae8e07-2be5-469f-8f0c-89fc0a0ac70a"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount = True)\n",
    "    %cd \"/content/drive/My Drive/automatic-asset-classification\"\n",
    "    %ls \"/content/drive/My Drive/automatic-asset-classification\"\n",
    "    image_path = \"/content/drive/My Drive/automatic-asset-classification/data/final_dataset\"\n",
    "    \n",
    "if not colab:\n",
    "    image_path = '/Users/henriwoodcock/Documents/Code/data_projects/automatic-asset-classification/data/'\\\n",
    "                 'final_dataset/final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0LB-1hseQFF"
   },
   "outputs": [],
   "source": [
    "size = 224\n",
    "batchsize = 32\n",
    "tfms = get_transforms(do_flip = False)\n",
    "src = (ImageImageList.from_folder(image_path, convert_mode = 'L').split_by_rand_pct(seed=2).label_from_func(lambda \n",
    "                                                                                                            x: x))\n",
    "data = (src.transform(size=size, tfm_y=True)\n",
    "        .databunch(bs=batchsize)\n",
    "        .normalize(do_y = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = (ImageImageList.from_folder(image_path, convert_mode = 'L').split_by_rand_pct(seed=2).\\\n",
    "       label_from_func(lambda x: x, convert_mode = 'L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (src.transform(size=size, tfm_y=True)\n",
    "        .databunch(bs=batchsize)\n",
    "        .normalize(do_y = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearAutoEncoder, self).__init__()\n",
    "        \n",
    "        self.layer_outs = [int(224*224//(6.125**i)) for i in range(6)];\n",
    "        self.enc = [];\n",
    "        self.dec = [];\n",
    "\n",
    "        for i in range(len(self.layer_outs) - 1):\n",
    "            self.enc += [\n",
    "                nn.Linear(self.layer_outs[i], self.layer_outs[i+1]),\n",
    "                nn.BatchNorm1d(self.layer_outs[i+1], eps=1e-05, momentum=0.1, affine=True, \n",
    "                               track_running_stats=True),\n",
    "                nn.Tanh()\n",
    "            ]\n",
    "            \n",
    "        self.layer_outs.reverse()\n",
    "        for i in range(len(self.layer_outs) - 1):\n",
    "            self.dec += [\n",
    "                nn.Linear(self.layer_outs[i], self.layer_outs[i+1]),\n",
    "                nn.BatchNorm1d(self.layer_outs[i+1], eps=1e-05, momentum=0.1, affine=True, \n",
    "                               track_running_stats=True),\n",
    "                nn.Tanh()\n",
    "            ]\n",
    "\n",
    "        self.encoder = nn.Sequential(*self.enc)\n",
    "        self.decoder = nn.Sequential(*self.dec)\n",
    "\n",
    "        \n",
    "    def encode(self, x): return self.encoder(x)\n",
    "    \n",
    "    def decode(self, x): return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 224**2)\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        decoded = decoded.reshape([-1,1,224,224])\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = LinearAutoEncoder();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, autoencoder, loss_func=F.mse_loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 8192]     411,049,984\n",
      "       BatchNorm1d-2                 [-1, 8192]          16,384\n",
      "              Tanh-3                 [-1, 8192]               0\n",
      "            Linear-4                 [-1, 1337]      10,954,041\n",
      "       BatchNorm1d-5                 [-1, 1337]           2,674\n",
      "              Tanh-6                 [-1, 1337]               0\n",
      "            Linear-7                  [-1, 218]         291,684\n",
      "       BatchNorm1d-8                  [-1, 218]             436\n",
      "              Tanh-9                  [-1, 218]               0\n",
      "           Linear-10                   [-1, 35]           7,665\n",
      "      BatchNorm1d-11                   [-1, 35]              70\n",
      "             Tanh-12                   [-1, 35]               0\n",
      "           Linear-13                    [-1, 5]             180\n",
      "      BatchNorm1d-14                    [-1, 5]              10\n",
      "             Tanh-15                    [-1, 5]               0\n",
      "           Linear-16                   [-1, 35]             210\n",
      "      BatchNorm1d-17                   [-1, 35]              70\n",
      "             Tanh-18                   [-1, 35]               0\n",
      "           Linear-19                  [-1, 218]           7,848\n",
      "      BatchNorm1d-20                  [-1, 218]             436\n",
      "             Tanh-21                  [-1, 218]               0\n",
      "           Linear-22                 [-1, 1337]         292,803\n",
      "      BatchNorm1d-23                 [-1, 1337]           2,674\n",
      "             Tanh-24                 [-1, 1337]               0\n",
      "           Linear-25                 [-1, 8192]      10,960,896\n",
      "      BatchNorm1d-26                 [-1, 8192]          16,384\n",
      "             Tanh-27                 [-1, 8192]               0\n",
      "           Linear-28                [-1, 50176]     411,091,968\n",
      "      BatchNorm1d-29                [-1, 50176]         100,352\n",
      "             Tanh-30                [-1, 50176]               0\n",
      "================================================================\n",
      "Total params: 844,796,769\n",
      "Trainable params: 844,796,769\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 1.60\n",
      "Params size (MB): 3222.64\n",
      "Estimated Total Size (MB): 3224.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(autoencoder, (1,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='13', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/13 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XzCQ1kWfecxq"
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False);\n",
    "        self.batch1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True);\n",
    "        \n",
    "        self.up1 = nn.Upsample(scale_factor = 2, mode = 'bilinear');\n",
    "        self.conv2 = nn.Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False);\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        return nn.Sequential(self.conv1, self.batch1, self.relu)(x)\n",
    "    \n",
    "    def decoder(self, x):\n",
    "        return nn.Sequential(self.up1,self.conv2, self.relu)(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (batch1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (up1): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  (conv2): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder2 = AutoEncoder();\n",
    "autoencoder2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2 = Learner(data, autoencoder2, loss_func=F.mse_loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (batch1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (up1): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  (conv2): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn2.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JItBtzIBeO2H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KNN-AutoEncoder-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
