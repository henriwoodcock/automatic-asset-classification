{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngMA7VJgdyqn"
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.tabular import *\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "from torch import nn\n",
    "import imageio\n",
    "import torch\n",
    "import glob\n",
    "from fastai.vision import *\n",
    "import os\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "7Lk3qLYqeM4n",
    "outputId": "5aae8e07-2be5-469f-8f0c-89fc0a0ac70a"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount = True)\n",
    "    %cd \"/content/drive/My Drive/automatic-asset-classification\"\n",
    "    %ls \"/content/drive/My Drive/automatic-asset-classification\"\n",
    "    image_path = \"/content/drive/My Drive/automatic-asset-classification/data/final_dataset\"\n",
    "    \n",
    "if not colab:\n",
    "    image_path = '/Users/henriwoodcock/Documents/Code/data_projects/automatic-asset-classification/data/'\\\n",
    "                 'final_dataset/final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0LB-1hseQFF"
   },
   "outputs": [],
   "source": [
    "size = 224\n",
    "batchsize = 32\n",
    "tfms = get_transforms(do_flip = False)\n",
    "src = (ImageImageList.from_folder(image_path, convert_mode = 'L').split_by_rand_pct(seed=2).label_from_func(lambda \n",
    "                                                                                                            x: x))\n",
    "data = (src.transform(size=size, tfm_y=True)\n",
    "        .databunch(bs=batchsize)\n",
    "        .normalize(imagenet_stats, do_y = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = (ImageImageList.from_folder(image_path, convert_mode = 'L').split_by_rand_pct(seed=2).\\\n",
    "       label_from_func(lambda x: x, convert_mode = 'L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (src.transform(size=size, tfm_y=True)\n",
    "        .databunch(bs=batchsize)\n",
    "        .normalize(imagenet_stats, do_y = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (444 items)\n",
       "x: ImageImageList\n",
       "Image (1, 224, 224),Image (1, 224, 224),Image (1, 224, 224),Image (1, 224, 224),Image (1, 224, 224)\n",
       "y: ImageList\n",
       "Image (1, 224, 224),Image (1, 224, 224),Image (1, 224, 224),Image (1, 224, 224),Image (1, 224, 224)\n",
       "Path: /Users/henriwoodcock/Documents/Code/data_projects/automatic-asset-classification/data/final_dataset/final;\n",
       "\n",
       "Valid: LabelList (110 items)\n",
       "x: ImageImageList\n",
       "Image (1, 224, 224),Image (1, 224, 224),Image (1, 224, 224),Image (1, 224, 224),Image (1, 224, 224)\n",
       "y: ImageList\n",
       "Image (1, 224, 224),Image (1, 224, 224),Image (1, 224, 224),Image (1, 224, 224),Image (1, 224, 224)\n",
       "Path: /Users/henriwoodcock/Documents/Code/data_projects/automatic-asset-classification/data/final_dataset/final;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearAutoEncoder, self).__init__()\n",
    "        \n",
    "        self.layer_outs = [int(224*224//(6.125**i)) for i in range(6)];\n",
    "        self.enc = [];\n",
    "        self.dec = [];\n",
    "\n",
    "        for i in range(len(self.layer_outs) - 1):\n",
    "            self.enc += [\n",
    "                nn.Linear(self.layer_outs[i], self.layer_outs[i+1]),\n",
    "                nn.BatchNorm1d(self.layer_outs[i+1], eps=1e-05, momentum=0.1, affine=True, \n",
    "                               track_running_stats=True),\n",
    "                nn.Tanh()\n",
    "            ]\n",
    "            \n",
    "        self.layer_outs.reverse()\n",
    "        for i in range(len(self.layer_outs) - 1):\n",
    "            self.dec += [\n",
    "                nn.Linear(self.layer_outs[i], self.layer_outs[i+1]),\n",
    "                nn.BatchNorm1d(self.layer_outs[i+1], eps=1e-05, momentum=0.1, affine=True, \n",
    "                               track_running_stats=True),\n",
    "                nn.Tanh()\n",
    "            ]\n",
    "\n",
    "        self.encoder = nn.Sequential(*self.enc)\n",
    "        self.decoder = nn.Sequential(*self.dec)\n",
    "\n",
    "        \n",
    "    def encode(self, x): return self.encoder(x)\n",
    "    \n",
    "    def decode(self, x): return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape([32, 224**2])\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        decoded = decoded.reshape([32,1,224,224])\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearAutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=50176, out_features=8192, bias=True)\n",
       "    (1): BatchNorm1d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Tanh()\n",
       "    (3): Linear(in_features=8192, out_features=1337, bias=True)\n",
       "    (4): BatchNorm1d(1337, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=1337, out_features=218, bias=True)\n",
       "    (7): BatchNorm1d(218, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): Tanh()\n",
       "    (9): Linear(in_features=218, out_features=35, bias=True)\n",
       "    (10): BatchNorm1d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Tanh()\n",
       "    (12): Linear(in_features=35, out_features=5, bias=True)\n",
       "    (13): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Tanh()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=35, bias=True)\n",
       "    (1): BatchNorm1d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Tanh()\n",
       "    (3): Linear(in_features=35, out_features=218, bias=True)\n",
       "    (4): BatchNorm1d(218, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=218, out_features=1337, bias=True)\n",
       "    (7): BatchNorm1d(1337, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): Tanh()\n",
       "    (9): Linear(in_features=1337, out_features=8192, bias=True)\n",
       "    (10): BatchNorm1d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Tanh()\n",
       "    (12): Linear(in_features=8192, out_features=50176, bias=True)\n",
       "    (13): BatchNorm1d(50176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = LinearAutoEncoder();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, autoencoder, loss_func=F.mse_loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[32, 50176]' is invalid for input of size 100352",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-de847ac7e3d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-c6d3571da8d4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[32, 50176]' is invalid for input of size 100352"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(autoencoder, (1,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XzCQ1kWfecxq"
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False);\n",
    "        self.batch1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True);\n",
    "        \n",
    "        self.up1 = nn.Upsample(scale_factor = 2, mode = 'bilinear');\n",
    "        self.conv2 = nn.Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False);\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        return nn.Sequential(self.conv1, self.batch1, self.relu)(x)\n",
    "    \n",
    "    def decoder(self, x):\n",
    "        return nn.Sequential(self.up1,self.conv2, self.relu)(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (batch1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (up1): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  (conv2): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder2 = AutoEncoder();\n",
    "autoencoder2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2 = Learner(data, autoencoder2, loss_func=F.mse_loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (batch1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (up1): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  (conv2): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn2.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JItBtzIBeO2H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KNN-AutoEncoder-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
